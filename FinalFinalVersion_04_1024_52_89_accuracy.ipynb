{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcFo7IHjD1Qb"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import copy\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Huya1sJwEliJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8793dc2-beb4-41de-a3aa-586bfeba05b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:10<00:00, 31876194.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 860106.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 22160177.18it/s]\n"
          ]
        }
      ],
      "source": [
        "# Define transformations and load datasets\n",
        "data_transforms = {\n",
        "    'train': v2.Compose([\n",
        "        v2.RandomRotation(45),\n",
        "        v2.RandomResizedCrop(224),\n",
        "        v2.RandomHorizontalFlip(),\n",
        "        v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        v2.RandomGrayscale(p=0.1),\n",
        "        v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "        v2.ToTensor(),\n",
        "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': v2.Compose([\n",
        "        v2.Resize(256),\n",
        "        v2.CenterCrop(224),\n",
        "        v2.ToTensor(),\n",
        "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': v2.Compose([\n",
        "        v2.Resize(256),\n",
        "        v2.CenterCrop(224),\n",
        "        v2.ToTensor(),\n",
        "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Specify the data directory\n",
        "data_path = \"data\"\n",
        "\n",
        "# Load the datasets\n",
        "flowers_train_data = datasets.Flowers102(root=data_path, split='train', download=True, transform=data_transforms['train'])\n",
        "flowers_val_data = datasets.Flowers102(root=data_path, split='val', download=True, transform=data_transforms['valid'])\n",
        "flowers_test_data = datasets.Flowers102(root=data_path, split='test', download=True, transform=data_transforms['test'])\n",
        "\n",
        "# Create data loaders\n",
        "dataloaders = {\n",
        "    'train': DataLoader(flowers_train_data, batch_size=128, shuffle=True),\n",
        "    'val': DataLoader(flowers_val_data, batch_size=128, shuffle=False),\n",
        "    'test': DataLoader(flowers_test_data, batch_size=128, shuffle=False)\n",
        "}\n",
        "\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(flowers_train_data),\n",
        "    'val': len(flowers_val_data),\n",
        "    'test': len(flowers_test_data)\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao4Z6_ZjMUVO"
      },
      "outputs": [],
      "source": [
        "# Define a Convolutional Neural Network\n",
        "class FlowerCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FlowerCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 1024)\n",
        "        self.bn6 = nn.BatchNorm1d(1024)\n",
        "        self.fc2 = nn.Linear(1024, 102)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.pool(torch.relu(self.bn5(self.conv5(x))))\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = self.dropout(torch.relu(self.bn6(self.fc1(x))))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZeRhKQyQo20"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXGDEZCeQmPL"
      },
      "outputs": [],
      "source": [
        "# Initialise the model\n",
        "\n",
        "model = FlowerCNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGkh2lujM5ci"
      },
      "outputs": [],
      "source": [
        "# Define a Loss Function, Optimizer and Learning Rate Scheduler\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plmenAf4Q_V1"
      },
      "outputs": [],
      "source": [
        "# Function to train the network\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=180):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print(' ' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data\n",
        "            phase_start_time = time.time()\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # Clear cache to free up memory\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            epoch_time = time.time() - phase_start_time\n",
        "\n",
        "            print('{} loss: {:.4f} accuracy: {:.4f} time: {:.0f}s'.format(\n",
        "                phase, epoch_loss, epoch_acc, epoch_time))\n",
        "\n",
        "            # Deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training completed in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best Validation Accuracy: {:4f}'.format(best_acc))\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn7l764TEz4u",
        "outputId": "3faec21b-62b5-456d-e3e3-e5e02dcbc26c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/180\n",
            "          \n",
            "train loss: 4.5242 accuracy: 0.0392 time: 18s\n",
            "val loss: 4.6271 accuracy: 0.0098 time: 7s\n",
            "\n",
            "Epoch 1/180\n",
            "          \n",
            "train loss: 4.0976 accuracy: 0.1088 time: 15s\n",
            "val loss: 4.4973 accuracy: 0.0373 time: 7s\n",
            "\n",
            "Epoch 2/180\n",
            "          \n",
            "train loss: 3.8299 accuracy: 0.1490 time: 15s\n",
            "val loss: 4.0932 accuracy: 0.0765 time: 7s\n",
            "\n",
            "Epoch 3/180\n",
            "          \n",
            "train loss: 3.6674 accuracy: 0.1824 time: 15s\n",
            "val loss: 3.6850 accuracy: 0.2039 time: 7s\n",
            "\n",
            "Epoch 4/180\n",
            "          \n",
            "train loss: 3.5753 accuracy: 0.2049 time: 15s\n",
            "val loss: 3.4839 accuracy: 0.2363 time: 7s\n",
            "\n",
            "Epoch 5/180\n",
            "          \n",
            "train loss: 3.5042 accuracy: 0.2147 time: 15s\n",
            "val loss: 3.4013 accuracy: 0.2412 time: 7s\n",
            "\n",
            "Epoch 6/180\n",
            "          \n",
            "train loss: 3.4167 accuracy: 0.2559 time: 15s\n",
            "val loss: 3.3689 accuracy: 0.2294 time: 7s\n",
            "\n",
            "Epoch 7/180\n",
            "          \n",
            "train loss: 3.4688 accuracy: 0.2382 time: 15s\n",
            "val loss: 3.3690 accuracy: 0.2245 time: 7s\n",
            "\n",
            "Epoch 8/180\n",
            "          \n",
            "train loss: 3.4556 accuracy: 0.2186 time: 15s\n",
            "val loss: 3.3513 accuracy: 0.2225 time: 7s\n",
            "\n",
            "Epoch 9/180\n",
            "          \n",
            "train loss: 3.4273 accuracy: 0.2275 time: 15s\n",
            "val loss: 3.3053 accuracy: 0.2461 time: 7s\n",
            "\n",
            "Epoch 10/180\n",
            "          \n",
            "train loss: 3.3551 accuracy: 0.2549 time: 16s\n",
            "val loss: 3.2624 accuracy: 0.2686 time: 7s\n",
            "\n",
            "Epoch 11/180\n",
            "          \n",
            "train loss: 3.3119 accuracy: 0.2549 time: 16s\n",
            "val loss: 3.1715 accuracy: 0.2941 time: 7s\n",
            "\n",
            "Epoch 12/180\n",
            "          \n",
            "train loss: 3.2381 accuracy: 0.2735 time: 15s\n",
            "val loss: 3.0731 accuracy: 0.3010 time: 7s\n",
            "\n",
            "Epoch 13/180\n",
            "          \n",
            "train loss: 3.1825 accuracy: 0.2853 time: 16s\n",
            "val loss: 3.0505 accuracy: 0.3010 time: 8s\n",
            "\n",
            "Epoch 14/180\n",
            "          \n",
            "train loss: 3.0759 accuracy: 0.3118 time: 16s\n",
            "val loss: 3.0045 accuracy: 0.2951 time: 8s\n",
            "\n",
            "Epoch 15/180\n",
            "          \n",
            "train loss: 3.0271 accuracy: 0.3363 time: 16s\n",
            "val loss: 2.9657 accuracy: 0.3108 time: 7s\n",
            "\n",
            "Epoch 16/180\n",
            "          \n",
            "train loss: 2.9708 accuracy: 0.3284 time: 16s\n",
            "val loss: 2.8621 accuracy: 0.3343 time: 7s\n",
            "\n",
            "Epoch 17/180\n",
            "          \n",
            "train loss: 2.9433 accuracy: 0.3578 time: 16s\n",
            "val loss: 2.8578 accuracy: 0.3539 time: 7s\n",
            "\n",
            "Epoch 18/180\n",
            "          \n",
            "train loss: 2.7991 accuracy: 0.3961 time: 16s\n",
            "val loss: 2.8016 accuracy: 0.3578 time: 7s\n",
            "\n",
            "Epoch 19/180\n",
            "          \n",
            "train loss: 2.7996 accuracy: 0.3686 time: 16s\n",
            "val loss: 2.7792 accuracy: 0.3559 time: 8s\n",
            "\n",
            "Epoch 20/180\n",
            "          \n",
            "train loss: 2.7995 accuracy: 0.3892 time: 16s\n",
            "val loss: 2.7532 accuracy: 0.3706 time: 7s\n",
            "\n",
            "Epoch 21/180\n",
            "          \n",
            "train loss: 2.7106 accuracy: 0.3922 time: 16s\n",
            "val loss: 2.7526 accuracy: 0.3706 time: 7s\n",
            "\n",
            "Epoch 22/180\n",
            "          \n",
            "train loss: 2.7763 accuracy: 0.3990 time: 16s\n",
            "val loss: 2.7419 accuracy: 0.3775 time: 8s\n",
            "\n",
            "Epoch 23/180\n",
            "          \n",
            "train loss: 2.7512 accuracy: 0.4010 time: 16s\n",
            "val loss: 2.7334 accuracy: 0.3608 time: 7s\n",
            "\n",
            "Epoch 24/180\n",
            "          \n",
            "train loss: 2.7456 accuracy: 0.3931 time: 16s\n",
            "val loss: 2.7267 accuracy: 0.3794 time: 7s\n",
            "\n",
            "Epoch 25/180\n",
            "          \n",
            "train loss: 2.6850 accuracy: 0.4118 time: 16s\n",
            "val loss: 2.7729 accuracy: 0.3765 time: 7s\n",
            "\n",
            "Epoch 26/180\n",
            "          \n",
            "train loss: 2.6754 accuracy: 0.4245 time: 16s\n",
            "val loss: 2.6916 accuracy: 0.4088 time: 7s\n",
            "\n",
            "Epoch 27/180\n",
            "          \n",
            "train loss: 2.7258 accuracy: 0.3922 time: 16s\n",
            "val loss: 2.7216 accuracy: 0.3696 time: 7s\n",
            "\n",
            "Epoch 28/180\n",
            "          \n",
            "train loss: 2.6251 accuracy: 0.4294 time: 16s\n",
            "val loss: 2.6959 accuracy: 0.3647 time: 8s\n",
            "\n",
            "Epoch 29/180\n",
            "          \n",
            "train loss: 2.6017 accuracy: 0.4245 time: 16s\n",
            "val loss: 2.6175 accuracy: 0.3843 time: 7s\n",
            "\n",
            "Epoch 30/180\n",
            "          \n",
            "train loss: 2.5503 accuracy: 0.4382 time: 16s\n",
            "val loss: 2.6296 accuracy: 0.3882 time: 7s\n",
            "\n",
            "Epoch 31/180\n",
            "          \n",
            "train loss: 2.5295 accuracy: 0.4500 time: 16s\n",
            "val loss: 2.6029 accuracy: 0.3961 time: 7s\n",
            "\n",
            "Epoch 32/180\n",
            "          \n",
            "train loss: 2.4691 accuracy: 0.4569 time: 16s\n",
            "val loss: 2.5134 accuracy: 0.4324 time: 7s\n",
            "\n",
            "Epoch 33/180\n",
            "          \n",
            "train loss: 2.4084 accuracy: 0.4647 time: 16s\n",
            "val loss: 2.4803 accuracy: 0.4490 time: 7s\n",
            "\n",
            "Epoch 34/180\n",
            "          \n",
            "train loss: 2.3898 accuracy: 0.4706 time: 16s\n",
            "val loss: 2.4897 accuracy: 0.4441 time: 7s\n",
            "\n",
            "Epoch 35/180\n",
            "          \n",
            "train loss: 2.3308 accuracy: 0.4990 time: 16s\n",
            "val loss: 2.4846 accuracy: 0.4461 time: 7s\n",
            "\n",
            "Epoch 36/180\n",
            "          \n",
            "train loss: 2.3570 accuracy: 0.4814 time: 16s\n",
            "val loss: 2.4931 accuracy: 0.4324 time: 7s\n",
            "\n",
            "Epoch 37/180\n",
            "          \n",
            "train loss: 2.3664 accuracy: 0.4588 time: 16s\n",
            "val loss: 2.4893 accuracy: 0.4206 time: 7s\n",
            "\n",
            "Epoch 38/180\n",
            "          \n",
            "train loss: 2.3395 accuracy: 0.4980 time: 16s\n",
            "val loss: 2.5009 accuracy: 0.4382 time: 7s\n",
            "\n",
            "Epoch 39/180\n",
            "          \n",
            "train loss: 2.3794 accuracy: 0.4667 time: 16s\n",
            "val loss: 2.4971 accuracy: 0.4294 time: 8s\n",
            "\n",
            "Epoch 40/180\n",
            "          \n",
            "train loss: 2.4011 accuracy: 0.4676 time: 16s\n",
            "val loss: 2.4699 accuracy: 0.4490 time: 8s\n",
            "\n",
            "Epoch 41/180\n",
            "          \n",
            "train loss: 2.4025 accuracy: 0.4784 time: 16s\n",
            "val loss: 2.4960 accuracy: 0.4196 time: 7s\n",
            "\n",
            "Epoch 42/180\n",
            "          \n",
            "train loss: 2.3670 accuracy: 0.4716 time: 16s\n",
            "val loss: 2.5283 accuracy: 0.4265 time: 7s\n",
            "\n",
            "Epoch 43/180\n",
            "          \n",
            "train loss: 2.2830 accuracy: 0.5010 time: 16s\n",
            "val loss: 2.4378 accuracy: 0.4412 time: 7s\n",
            "\n",
            "Epoch 44/180\n",
            "          \n",
            "train loss: 2.3224 accuracy: 0.4853 time: 16s\n",
            "val loss: 2.4350 accuracy: 0.4333 time: 7s\n",
            "\n",
            "Epoch 45/180\n",
            "          \n",
            "train loss: 2.2881 accuracy: 0.4931 time: 16s\n",
            "val loss: 2.3495 accuracy: 0.4608 time: 7s\n",
            "\n",
            "Epoch 46/180\n",
            "          \n",
            "train loss: 2.1947 accuracy: 0.5186 time: 16s\n",
            "val loss: 2.3692 accuracy: 0.4461 time: 7s\n",
            "\n",
            "Epoch 47/180\n",
            "          \n",
            "train loss: 2.1278 accuracy: 0.5255 time: 16s\n",
            "val loss: 2.3498 accuracy: 0.4559 time: 7s\n",
            "\n",
            "Epoch 48/180\n",
            "          \n",
            "train loss: 2.2099 accuracy: 0.5069 time: 16s\n",
            "val loss: 2.3248 accuracy: 0.4667 time: 7s\n",
            "\n",
            "Epoch 49/180\n",
            "          \n",
            "train loss: 2.1668 accuracy: 0.5235 time: 16s\n",
            "val loss: 2.3245 accuracy: 0.4647 time: 7s\n",
            "\n",
            "Epoch 50/180\n",
            "          \n",
            "train loss: 2.1018 accuracy: 0.5559 time: 16s\n",
            "val loss: 2.3121 accuracy: 0.4637 time: 7s\n",
            "\n",
            "Epoch 51/180\n",
            "          \n",
            "train loss: 2.1276 accuracy: 0.5363 time: 15s\n",
            "val loss: 2.3203 accuracy: 0.4696 time: 7s\n",
            "\n",
            "Epoch 52/180\n",
            "          \n",
            "train loss: 2.0466 accuracy: 0.5676 time: 16s\n",
            "val loss: 2.3484 accuracy: 0.4696 time: 7s\n",
            "\n",
            "Epoch 53/180\n",
            "          \n",
            "train loss: 2.0717 accuracy: 0.5569 time: 16s\n",
            "val loss: 2.3514 accuracy: 0.4461 time: 7s\n",
            "\n",
            "Epoch 54/180\n",
            "          \n",
            "train loss: 2.0876 accuracy: 0.5510 time: 16s\n",
            "val loss: 2.3496 accuracy: 0.4500 time: 7s\n",
            "\n",
            "Epoch 55/180\n",
            "          \n",
            "train loss: 2.1039 accuracy: 0.5382 time: 16s\n",
            "val loss: 2.4113 accuracy: 0.4431 time: 7s\n",
            "\n",
            "Epoch 56/180\n",
            "          \n",
            "train loss: 2.1712 accuracy: 0.5186 time: 15s\n",
            "val loss: 2.5069 accuracy: 0.4157 time: 7s\n",
            "\n",
            "Epoch 57/180\n",
            "          \n",
            "train loss: 2.1118 accuracy: 0.5343 time: 16s\n",
            "val loss: 2.3334 accuracy: 0.4333 time: 7s\n",
            "\n",
            "Epoch 58/180\n",
            "          \n",
            "train loss: 2.0780 accuracy: 0.5559 time: 16s\n",
            "val loss: 2.3657 accuracy: 0.4520 time: 7s\n",
            "\n",
            "Epoch 59/180\n",
            "          \n",
            "train loss: 2.0593 accuracy: 0.5510 time: 16s\n",
            "val loss: 2.2529 accuracy: 0.4902 time: 7s\n",
            "\n",
            "Epoch 60/180\n",
            "          \n",
            "train loss: 1.9675 accuracy: 0.5765 time: 16s\n",
            "val loss: 2.2320 accuracy: 0.4892 time: 7s\n",
            "\n",
            "Epoch 61/180\n",
            "          \n",
            "train loss: 1.9690 accuracy: 0.5618 time: 15s\n",
            "val loss: 2.2168 accuracy: 0.4931 time: 7s\n",
            "\n",
            "Epoch 62/180\n",
            "          \n",
            "train loss: 1.8825 accuracy: 0.5980 time: 16s\n",
            "val loss: 2.2107 accuracy: 0.4882 time: 7s\n",
            "\n",
            "Epoch 63/180\n",
            "          \n",
            "train loss: 1.8916 accuracy: 0.5961 time: 16s\n",
            "val loss: 2.2002 accuracy: 0.4892 time: 7s\n",
            "\n",
            "Epoch 64/180\n",
            "          \n",
            "train loss: 1.8974 accuracy: 0.6029 time: 16s\n",
            "val loss: 2.1952 accuracy: 0.4902 time: 7s\n",
            "\n",
            "Epoch 65/180\n",
            "          \n",
            "train loss: 1.8489 accuracy: 0.6157 time: 16s\n",
            "val loss: 2.2035 accuracy: 0.4902 time: 7s\n",
            "\n",
            "Epoch 66/180\n",
            "          \n",
            "train loss: 1.9274 accuracy: 0.5882 time: 16s\n",
            "val loss: 2.2349 accuracy: 0.4824 time: 7s\n",
            "\n",
            "Epoch 67/180\n",
            "          \n",
            "train loss: 1.9023 accuracy: 0.5912 time: 16s\n",
            "val loss: 2.2149 accuracy: 0.4902 time: 7s\n",
            "\n",
            "Epoch 68/180\n",
            "          \n",
            "train loss: 1.9314 accuracy: 0.5833 time: 16s\n",
            "val loss: 2.2468 accuracy: 0.4598 time: 7s\n",
            "\n",
            "Epoch 69/180\n",
            "          \n",
            "train loss: 1.9649 accuracy: 0.5559 time: 16s\n",
            "val loss: 2.3093 accuracy: 0.4549 time: 7s\n",
            "\n",
            "Epoch 70/180\n",
            "          \n",
            "train loss: 1.9923 accuracy: 0.5873 time: 16s\n",
            "val loss: 2.2366 accuracy: 0.4745 time: 7s\n",
            "\n",
            "Epoch 71/180\n",
            "          \n",
            "train loss: 1.8652 accuracy: 0.5824 time: 16s\n",
            "val loss: 2.3230 accuracy: 0.4657 time: 7s\n",
            "\n",
            "Epoch 72/180\n",
            "          \n",
            "train loss: 1.9426 accuracy: 0.5863 time: 16s\n",
            "val loss: 2.2137 accuracy: 0.4814 time: 7s\n",
            "\n",
            "Epoch 73/180\n",
            "          \n",
            "train loss: 1.9053 accuracy: 0.5804 time: 16s\n",
            "val loss: 2.1762 accuracy: 0.4755 time: 7s\n",
            "\n",
            "Epoch 74/180\n",
            "          \n",
            "train loss: 1.8350 accuracy: 0.5892 time: 16s\n",
            "val loss: 2.1588 accuracy: 0.4922 time: 7s\n",
            "\n",
            "Epoch 75/180\n",
            "          \n",
            "train loss: 1.7632 accuracy: 0.6245 time: 16s\n",
            "val loss: 2.1358 accuracy: 0.4902 time: 7s\n",
            "\n",
            "Epoch 76/180\n",
            "          \n",
            "train loss: 1.7656 accuracy: 0.6206 time: 16s\n",
            "val loss: 2.1174 accuracy: 0.5029 time: 7s\n",
            "\n",
            "Epoch 77/180\n",
            "          \n",
            "train loss: 1.7518 accuracy: 0.6245 time: 16s\n",
            "val loss: 2.1065 accuracy: 0.4980 time: 7s\n",
            "\n",
            "Epoch 78/180\n",
            "          \n",
            "train loss: 1.7618 accuracy: 0.6333 time: 16s\n",
            "val loss: 2.0958 accuracy: 0.5039 time: 7s\n",
            "\n",
            "Epoch 79/180\n",
            "          \n",
            "train loss: 1.7132 accuracy: 0.6412 time: 16s\n",
            "val loss: 2.1032 accuracy: 0.4980 time: 7s\n",
            "\n",
            "Epoch 80/180\n",
            "          \n",
            "train loss: 1.7216 accuracy: 0.6451 time: 16s\n",
            "val loss: 2.1156 accuracy: 0.5088 time: 7s\n",
            "\n",
            "Epoch 81/180\n",
            "          \n",
            "train loss: 1.8387 accuracy: 0.6078 time: 16s\n",
            "val loss: 2.1120 accuracy: 0.4922 time: 7s\n",
            "\n",
            "Epoch 82/180\n",
            "          \n",
            "train loss: 1.6884 accuracy: 0.6206 time: 16s\n",
            "val loss: 2.1886 accuracy: 0.4833 time: 7s\n",
            "\n",
            "Epoch 83/180\n",
            "          \n",
            "train loss: 1.7804 accuracy: 0.6225 time: 16s\n",
            "val loss: 2.1952 accuracy: 0.4775 time: 7s\n",
            "\n",
            "Epoch 84/180\n",
            "          \n",
            "train loss: 1.7591 accuracy: 0.6127 time: 16s\n",
            "val loss: 2.1961 accuracy: 0.4725 time: 7s\n",
            "\n",
            "Epoch 85/180\n",
            "          \n",
            "train loss: 1.8085 accuracy: 0.6078 time: 16s\n",
            "val loss: 2.1763 accuracy: 0.4941 time: 7s\n",
            "\n",
            "Epoch 86/180\n",
            "          \n",
            "train loss: 1.7311 accuracy: 0.6196 time: 16s\n",
            "val loss: 2.1976 accuracy: 0.4853 time: 7s\n",
            "\n",
            "Epoch 87/180\n",
            "          \n",
            "train loss: 1.7191 accuracy: 0.6412 time: 16s\n",
            "val loss: 2.0860 accuracy: 0.5147 time: 7s\n",
            "\n",
            "Epoch 88/180\n",
            "          \n",
            "train loss: 1.6702 accuracy: 0.6324 time: 16s\n",
            "val loss: 2.0825 accuracy: 0.5088 time: 7s\n",
            "\n",
            "Epoch 89/180\n",
            "          \n",
            "train loss: 1.6431 accuracy: 0.6647 time: 16s\n",
            "val loss: 2.0654 accuracy: 0.5098 time: 7s\n",
            "\n",
            "Epoch 90/180\n",
            "          \n",
            "train loss: 1.6312 accuracy: 0.6627 time: 16s\n",
            "val loss: 2.0508 accuracy: 0.5127 time: 7s\n",
            "\n",
            "Epoch 91/180\n",
            "          \n",
            "train loss: 1.6134 accuracy: 0.6676 time: 16s\n",
            "val loss: 2.0448 accuracy: 0.5108 time: 7s\n",
            "\n",
            "Epoch 92/180\n",
            "          \n",
            "train loss: 1.5379 accuracy: 0.6922 time: 16s\n",
            "val loss: 2.0446 accuracy: 0.5176 time: 7s\n",
            "\n",
            "Epoch 93/180\n",
            "          \n",
            "train loss: 1.5428 accuracy: 0.6794 time: 16s\n",
            "val loss: 2.0532 accuracy: 0.5206 time: 7s\n",
            "\n",
            "Epoch 94/180\n",
            "          \n",
            "train loss: 1.5616 accuracy: 0.6873 time: 16s\n",
            "val loss: 2.0474 accuracy: 0.5157 time: 7s\n",
            "\n",
            "Epoch 95/180\n",
            "          \n",
            "train loss: 1.6067 accuracy: 0.6578 time: 16s\n",
            "val loss: 2.0746 accuracy: 0.5020 time: 7s\n",
            "\n",
            "Epoch 96/180\n",
            "          \n",
            "train loss: 1.6090 accuracy: 0.6627 time: 16s\n",
            "val loss: 2.1604 accuracy: 0.4892 time: 7s\n",
            "\n",
            "Epoch 97/180\n",
            "          \n",
            "train loss: 1.6423 accuracy: 0.6441 time: 16s\n",
            "val loss: 2.0965 accuracy: 0.5039 time: 7s\n",
            "\n",
            "Epoch 98/180\n",
            "          \n",
            "train loss: 1.6843 accuracy: 0.6412 time: 16s\n",
            "val loss: 2.1398 accuracy: 0.4853 time: 7s\n",
            "\n",
            "Epoch 99/180\n",
            "          \n",
            "train loss: 1.6758 accuracy: 0.6647 time: 16s\n",
            "val loss: 2.1261 accuracy: 0.4873 time: 7s\n",
            "\n",
            "Epoch 100/180\n",
            "          \n",
            "train loss: 1.6806 accuracy: 0.6343 time: 16s\n",
            "val loss: 2.2271 accuracy: 0.4608 time: 7s\n",
            "\n",
            "Epoch 101/180\n",
            "          \n",
            "train loss: 1.6242 accuracy: 0.6549 time: 16s\n",
            "val loss: 2.0620 accuracy: 0.5059 time: 7s\n",
            "\n",
            "Epoch 102/180\n",
            "          \n",
            "train loss: 1.5533 accuracy: 0.6686 time: 16s\n",
            "val loss: 2.0638 accuracy: 0.5049 time: 7s\n",
            "\n",
            "Epoch 103/180\n",
            "          \n",
            "train loss: 1.5252 accuracy: 0.6804 time: 16s\n",
            "val loss: 1.9690 accuracy: 0.5343 time: 7s\n",
            "\n",
            "Epoch 104/180\n",
            "          \n",
            "train loss: 1.5261 accuracy: 0.6735 time: 16s\n",
            "val loss: 1.9562 accuracy: 0.5333 time: 7s\n",
            "\n",
            "Epoch 105/180\n",
            "          \n",
            "train loss: 1.4804 accuracy: 0.6971 time: 16s\n",
            "val loss: 1.9563 accuracy: 0.5343 time: 7s\n",
            "\n",
            "Epoch 106/180\n",
            "          \n",
            "train loss: 1.4937 accuracy: 0.6853 time: 16s\n",
            "val loss: 1.9660 accuracy: 0.5382 time: 7s\n",
            "\n",
            "Epoch 107/180\n",
            "          \n",
            "train loss: 1.4676 accuracy: 0.6971 time: 16s\n",
            "val loss: 2.0040 accuracy: 0.5235 time: 7s\n",
            "\n",
            "Epoch 108/180\n",
            "          \n",
            "train loss: 1.4270 accuracy: 0.7157 time: 16s\n",
            "val loss: 2.0385 accuracy: 0.5118 time: 7s\n",
            "\n",
            "Epoch 109/180\n",
            "          \n",
            "train loss: 1.4975 accuracy: 0.6814 time: 16s\n",
            "val loss: 2.0319 accuracy: 0.5216 time: 7s\n",
            "\n",
            "Epoch 110/180\n",
            "          \n",
            "train loss: 1.5284 accuracy: 0.6627 time: 16s\n",
            "val loss: 2.0562 accuracy: 0.5039 time: 7s\n",
            "\n",
            "Epoch 111/180\n",
            "          \n",
            "train loss: 1.5232 accuracy: 0.6706 time: 16s\n",
            "val loss: 2.0424 accuracy: 0.5186 time: 7s\n",
            "\n",
            "Epoch 112/180\n",
            "          \n",
            "train loss: 1.5296 accuracy: 0.6784 time: 16s\n",
            "val loss: 2.1738 accuracy: 0.4706 time: 7s\n",
            "\n",
            "Epoch 113/180\n",
            "          \n",
            "train loss: 1.4972 accuracy: 0.6853 time: 16s\n",
            "val loss: 2.1043 accuracy: 0.5078 time: 7s\n",
            "\n",
            "Epoch 114/180\n",
            "          \n",
            "train loss: 1.5357 accuracy: 0.6833 time: 16s\n",
            "val loss: 2.0833 accuracy: 0.4863 time: 7s\n",
            "\n",
            "Epoch 115/180\n",
            "          \n",
            "train loss: 1.5326 accuracy: 0.6657 time: 16s\n",
            "val loss: 2.0091 accuracy: 0.5078 time: 7s\n",
            "\n",
            "Epoch 116/180\n",
            "          \n",
            "train loss: 1.3863 accuracy: 0.7157 time: 16s\n",
            "val loss: 1.9603 accuracy: 0.5451 time: 7s\n",
            "\n",
            "Epoch 117/180\n",
            "          \n",
            "train loss: 1.3978 accuracy: 0.7216 time: 16s\n",
            "val loss: 1.9394 accuracy: 0.5520 time: 7s\n",
            "\n",
            "Epoch 118/180\n",
            "          \n",
            "train loss: 1.4115 accuracy: 0.7235 time: 16s\n",
            "val loss: 1.9384 accuracy: 0.5510 time: 7s\n",
            "\n",
            "Epoch 119/180\n",
            "          \n",
            "train loss: 1.4028 accuracy: 0.7147 time: 16s\n",
            "val loss: 1.9224 accuracy: 0.5529 time: 7s\n",
            "\n",
            "Epoch 120/180\n",
            "          \n",
            "train loss: 1.3567 accuracy: 0.7294 time: 16s\n",
            "val loss: 1.9170 accuracy: 0.5529 time: 7s\n",
            "\n",
            "Epoch 121/180\n",
            "          \n",
            "train loss: 1.4793 accuracy: 0.6843 time: 16s\n",
            "val loss: 1.9130 accuracy: 0.5392 time: 7s\n",
            "\n",
            "Epoch 122/180\n",
            "          \n",
            "train loss: 1.3666 accuracy: 0.7196 time: 16s\n",
            "val loss: 1.9549 accuracy: 0.5324 time: 7s\n",
            "\n",
            "Epoch 123/180\n",
            "          \n",
            "train loss: 1.3637 accuracy: 0.7186 time: 16s\n",
            "val loss: 1.9537 accuracy: 0.5363 time: 7s\n",
            "\n",
            "Epoch 124/180\n",
            "          \n",
            "train loss: 1.4269 accuracy: 0.6980 time: 16s\n",
            "val loss: 2.0171 accuracy: 0.5137 time: 7s\n",
            "\n",
            "Epoch 125/180\n",
            "          \n",
            "train loss: 1.3743 accuracy: 0.7147 time: 16s\n",
            "val loss: 2.1143 accuracy: 0.4941 time: 7s\n",
            "\n",
            "Epoch 126/180\n",
            "          \n",
            "train loss: 1.4409 accuracy: 0.6892 time: 16s\n",
            "val loss: 2.1356 accuracy: 0.4902 time: 7s\n",
            "\n",
            "Epoch 127/180\n",
            "          \n",
            "train loss: 1.4885 accuracy: 0.6696 time: 16s\n",
            "val loss: 2.0711 accuracy: 0.4931 time: 7s\n",
            "\n",
            "Epoch 128/180\n",
            "          \n",
            "train loss: 1.4392 accuracy: 0.6824 time: 16s\n",
            "val loss: 2.0132 accuracy: 0.5196 time: 7s\n",
            "\n",
            "Epoch 129/180\n",
            "          \n",
            "train loss: 1.4212 accuracy: 0.7049 time: 16s\n",
            "val loss: 2.0114 accuracy: 0.5186 time: 7s\n",
            "\n",
            "Epoch 130/180\n",
            "          \n",
            "train loss: 1.4399 accuracy: 0.7078 time: 16s\n",
            "val loss: 1.9454 accuracy: 0.5402 time: 7s\n",
            "\n",
            "Epoch 131/180\n",
            "          \n",
            "train loss: 1.3848 accuracy: 0.7225 time: 16s\n",
            "val loss: 1.9131 accuracy: 0.5392 time: 7s\n",
            "\n",
            "Epoch 132/180\n",
            "          \n",
            "train loss: 1.3386 accuracy: 0.7216 time: 16s\n",
            "val loss: 1.9013 accuracy: 0.5402 time: 7s\n",
            "\n",
            "Epoch 133/180\n",
            "          \n",
            "train loss: 1.2777 accuracy: 0.7422 time: 16s\n",
            "val loss: 1.8994 accuracy: 0.5402 time: 7s\n",
            "\n",
            "Epoch 134/180\n",
            "          \n",
            "train loss: 1.2917 accuracy: 0.7353 time: 16s\n",
            "val loss: 1.8882 accuracy: 0.5441 time: 7s\n",
            "\n",
            "Epoch 135/180\n",
            "          \n",
            "train loss: 1.2676 accuracy: 0.7412 time: 16s\n",
            "val loss: 1.8816 accuracy: 0.5441 time: 7s\n",
            "\n",
            "Epoch 136/180\n",
            "          \n",
            "train loss: 1.3054 accuracy: 0.7382 time: 16s\n",
            "val loss: 1.9072 accuracy: 0.5500 time: 7s\n",
            "\n",
            "Epoch 137/180\n",
            "          \n",
            "train loss: 1.3251 accuracy: 0.7245 time: 16s\n",
            "val loss: 1.9123 accuracy: 0.5539 time: 7s\n",
            "\n",
            "Epoch 138/180\n",
            "          \n",
            "train loss: 1.3501 accuracy: 0.7265 time: 16s\n",
            "val loss: 1.9768 accuracy: 0.5225 time: 7s\n",
            "\n",
            "Epoch 139/180\n",
            "          \n",
            "train loss: 1.3294 accuracy: 0.7294 time: 16s\n",
            "val loss: 1.9884 accuracy: 0.5147 time: 7s\n",
            "\n",
            "Epoch 140/180\n",
            "          \n",
            "train loss: 1.4334 accuracy: 0.6853 time: 16s\n",
            "val loss: 2.1123 accuracy: 0.4902 time: 7s\n",
            "\n",
            "Epoch 141/180\n",
            "          \n",
            "train loss: 1.4794 accuracy: 0.6647 time: 16s\n",
            "val loss: 1.9964 accuracy: 0.5225 time: 7s\n",
            "\n",
            "Epoch 142/180\n",
            "          \n",
            "train loss: 1.3715 accuracy: 0.7020 time: 16s\n",
            "val loss: 2.0190 accuracy: 0.5265 time: 7s\n",
            "\n",
            "Epoch 143/180\n",
            "          \n",
            "train loss: 1.2807 accuracy: 0.7284 time: 16s\n",
            "val loss: 1.9574 accuracy: 0.5441 time: 7s\n",
            "\n",
            "Epoch 144/180\n",
            "          \n",
            "train loss: 1.3180 accuracy: 0.7235 time: 16s\n",
            "val loss: 1.9508 accuracy: 0.5147 time: 7s\n",
            "\n",
            "Epoch 145/180\n",
            "          \n",
            "train loss: 1.2959 accuracy: 0.7137 time: 16s\n",
            "val loss: 1.8739 accuracy: 0.5363 time: 7s\n",
            "\n",
            "Epoch 146/180\n",
            "          \n",
            "train loss: 1.2367 accuracy: 0.7314 time: 16s\n",
            "val loss: 1.8585 accuracy: 0.5431 time: 7s\n",
            "\n",
            "Epoch 147/180\n",
            "          \n",
            "train loss: 1.2628 accuracy: 0.7392 time: 16s\n",
            "val loss: 1.8554 accuracy: 0.5520 time: 7s\n",
            "\n",
            "Epoch 148/180\n",
            "          \n",
            "train loss: 1.2399 accuracy: 0.7520 time: 16s\n",
            "val loss: 1.8609 accuracy: 0.5510 time: 7s\n",
            "\n",
            "Epoch 149/180\n",
            "          \n",
            "train loss: 1.2076 accuracy: 0.7647 time: 16s\n",
            "val loss: 1.8703 accuracy: 0.5471 time: 7s\n",
            "\n",
            "Epoch 150/180\n",
            "          \n",
            "train loss: 1.1906 accuracy: 0.7500 time: 16s\n",
            "val loss: 1.8593 accuracy: 0.5588 time: 7s\n",
            "\n",
            "Epoch 151/180\n",
            "          \n",
            "train loss: 1.2096 accuracy: 0.7559 time: 16s\n",
            "val loss: 1.8922 accuracy: 0.5618 time: 7s\n",
            "\n",
            "Epoch 152/180\n",
            "          \n",
            "train loss: 1.2513 accuracy: 0.7343 time: 16s\n",
            "val loss: 1.9152 accuracy: 0.5480 time: 7s\n",
            "\n",
            "Epoch 153/180\n",
            "          \n",
            "train loss: 1.2468 accuracy: 0.7431 time: 16s\n",
            "val loss: 2.0456 accuracy: 0.5010 time: 7s\n",
            "\n",
            "Epoch 154/180\n",
            "          \n",
            "train loss: 1.3319 accuracy: 0.7167 time: 16s\n",
            "val loss: 2.0468 accuracy: 0.4990 time: 7s\n",
            "\n",
            "Epoch 155/180\n",
            "          \n",
            "train loss: 1.2376 accuracy: 0.7324 time: 16s\n",
            "val loss: 1.9841 accuracy: 0.5275 time: 7s\n",
            "\n",
            "Epoch 156/180\n",
            "          \n",
            "train loss: 1.3379 accuracy: 0.7245 time: 16s\n",
            "val loss: 1.9670 accuracy: 0.5235 time: 7s\n",
            "\n",
            "Epoch 157/180\n",
            "          \n",
            "train loss: 1.2795 accuracy: 0.7225 time: 16s\n",
            "val loss: 1.8968 accuracy: 0.5412 time: 7s\n",
            "\n",
            "Epoch 158/180\n",
            "          \n",
            "train loss: 1.2102 accuracy: 0.7559 time: 16s\n",
            "val loss: 1.8601 accuracy: 0.5510 time: 7s\n",
            "\n",
            "Epoch 159/180\n",
            "          \n",
            "train loss: 1.2152 accuracy: 0.7480 time: 16s\n",
            "val loss: 1.8581 accuracy: 0.5549 time: 7s\n",
            "\n",
            "Epoch 160/180\n",
            "          \n",
            "train loss: 1.1101 accuracy: 0.7588 time: 16s\n",
            "val loss: 1.8295 accuracy: 0.5608 time: 7s\n",
            "\n",
            "Epoch 161/180\n",
            "          \n",
            "train loss: 1.2005 accuracy: 0.7471 time: 16s\n",
            "val loss: 1.8227 accuracy: 0.5647 time: 7s\n",
            "\n",
            "Epoch 162/180\n",
            "          \n",
            "train loss: 1.1750 accuracy: 0.7647 time: 16s\n",
            "val loss: 1.8133 accuracy: 0.5647 time: 7s\n",
            "\n",
            "Epoch 163/180\n",
            "          \n",
            "train loss: 1.1379 accuracy: 0.7725 time: 16s\n",
            "val loss: 1.8204 accuracy: 0.5725 time: 7s\n",
            "\n",
            "Epoch 164/180\n",
            "          \n",
            "train loss: 1.0989 accuracy: 0.7755 time: 16s\n",
            "val loss: 1.8748 accuracy: 0.5588 time: 7s\n",
            "\n",
            "Epoch 165/180\n",
            "          \n",
            "train loss: 1.2131 accuracy: 0.7422 time: 16s\n",
            "val loss: 1.9248 accuracy: 0.5422 time: 7s\n",
            "\n",
            "Epoch 166/180\n",
            "          \n",
            "train loss: 1.1582 accuracy: 0.7686 time: 16s\n",
            "val loss: 1.9118 accuracy: 0.5500 time: 7s\n",
            "\n",
            "Epoch 167/180\n",
            "          \n",
            "train loss: 1.1742 accuracy: 0.7559 time: 16s\n",
            "val loss: 1.9316 accuracy: 0.5294 time: 7s\n",
            "\n",
            "Epoch 168/180\n",
            "          \n",
            "train loss: 1.1575 accuracy: 0.7569 time: 16s\n",
            "val loss: 1.8913 accuracy: 0.5382 time: 7s\n",
            "\n",
            "Epoch 169/180\n",
            "          \n",
            "train loss: 1.2680 accuracy: 0.7196 time: 16s\n",
            "val loss: 1.9643 accuracy: 0.5225 time: 7s\n",
            "\n",
            "Epoch 170/180\n",
            "          \n",
            "train loss: 1.2146 accuracy: 0.7392 time: 16s\n",
            "val loss: 1.9297 accuracy: 0.5422 time: 7s\n",
            "\n",
            "Epoch 171/180\n",
            "          \n",
            "train loss: 1.1253 accuracy: 0.7706 time: 16s\n",
            "val loss: 1.8195 accuracy: 0.5588 time: 7s\n",
            "\n",
            "Epoch 172/180\n",
            "          \n",
            "train loss: 1.1566 accuracy: 0.7588 time: 16s\n",
            "val loss: 1.8318 accuracy: 0.5539 time: 7s\n",
            "\n",
            "Epoch 173/180\n",
            "          \n",
            "train loss: 1.1320 accuracy: 0.7608 time: 16s\n",
            "val loss: 1.8126 accuracy: 0.5647 time: 7s\n",
            "\n",
            "Epoch 174/180\n",
            "          \n",
            "train loss: 1.0261 accuracy: 0.7912 time: 16s\n",
            "val loss: 1.8021 accuracy: 0.5667 time: 7s\n",
            "\n",
            "Epoch 175/180\n",
            "          \n",
            "train loss: 1.0683 accuracy: 0.7784 time: 16s\n",
            "val loss: 1.7993 accuracy: 0.5647 time: 7s\n",
            "\n",
            "Epoch 176/180\n",
            "          \n",
            "train loss: 1.0679 accuracy: 0.7716 time: 16s\n",
            "val loss: 1.8033 accuracy: 0.5647 time: 7s\n",
            "\n",
            "Epoch 177/180\n",
            "          \n",
            "train loss: 1.1141 accuracy: 0.7667 time: 16s\n",
            "val loss: 1.8140 accuracy: 0.5706 time: 7s\n",
            "\n",
            "Epoch 178/180\n",
            "          \n",
            "train loss: 0.9920 accuracy: 0.8029 time: 16s\n",
            "val loss: 1.8030 accuracy: 0.5725 time: 7s\n",
            "\n",
            "Epoch 179/180\n",
            "          \n",
            "train loss: 1.0734 accuracy: 0.7775 time: 16s\n",
            "val loss: 1.8816 accuracy: 0.5549 time: 7s\n",
            "\n",
            "Training completed in 69m 3s\n",
            "Best Validation Accuracy: 0.572549\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=180)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained mode\n",
        "torch.save(model.state_dict(), 'flowers102_classifier_model.pth')"
      ],
      "metadata": {
        "id": "OFbbzh1pKQA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyy3IzNWXC-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb3c698-023c-413d-9c44-7be92d60cde8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FlowerCNN(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc1): Linear(in_features=25088, out_features=1024, bias=True)\n",
              "  (bn6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=102, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the trained model\n",
        "model.load_state_dict(torch.load('flowers102_classifier_model.pth'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdRDg-LvagI8"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate the model\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9xqGfJHcPp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556542e1-dc47-4432-d591-d6e91e306195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 52.89%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_accuracy = evaluate_model(model, dataloaders['test'])\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJe6kQGVcJvN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}