{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UfWCGRaovX-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import copy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations and load datasets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "     ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Specify the data directory\n",
        "data_path = \"data\"\n",
        "\n",
        "# Load the datasets with the corresponding transformations\n",
        "flowers_train_data = datasets.Flowers102(root=data_path, split='train', download=True, transform=data_transforms['train'])\n",
        "flowers_val_data = datasets.Flowers102(root=data_path, split='val', download=True, transform=data_transforms['valid'])\n",
        "flowers_test_data = datasets.Flowers102(root=data_path, split='test', download=True, transform=data_transforms['test'])\n",
        "\n",
        "# Create data loaders for each split with specific batch size and shuffling settings\n",
        "dataloaders = {\n",
        "    'train': DataLoader(flowers_train_data, batch_size=128, shuffle=True),\n",
        "    'val': DataLoader(flowers_val_data, batch_size=128, shuffle=False),\n",
        "    'test': DataLoader(flowers_test_data, batch_size=128, shuffle=False)\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(flowers_train_data),\n",
        "    'val': len(flowers_val_data),\n",
        "    'test': len(flowers_test_data)\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMoavH2awIyG",
        "outputId": "cba00ba8-a4d3-49b0-cf9f-e507999043a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:10<00:00, 32311859.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 816417.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 21369280.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es4eZuddo14I"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "class FlowerCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FlowerCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
        "        self.bn6 = nn.BatchNorm1d(4096)\n",
        "        self.fc2 = nn.Linear(4096, 102)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.pool(torch.relu(self.bn5(self.conv5(x))))\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = self.dropout(torch.relu(self.bn6(self.fc1(x))))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "UK8OTrIUjOaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bkZiut65hcm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = FlowerCNN().to(device)\n"
      ],
      "metadata": {
        "id": "7FmWti-KhfpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "vd-n9Dn5hjlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Decay learning rate by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=7)\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=150):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                # Track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} loss: {:.4f} accuracy: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # Deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training completed in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val accuracy: {:4f}'.format(best_acc))\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ5pZP_shakO",
        "outputId": "577ad42d-0159-48b1-8c91-6a6710957517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/149\n",
            "----------\n",
            "train loss: 4.3614 accuracy: 0.0529\n",
            "val loss: 4.6725 accuracy: 0.0098\n",
            "\n",
            "Epoch 1/149\n",
            "----------\n",
            "train loss: 3.5426 accuracy: 0.1716\n",
            "val loss: 4.7031 accuracy: 0.0245\n",
            "\n",
            "Epoch 2/149\n",
            "----------\n",
            "train loss: 3.2023 accuracy: 0.2255\n",
            "val loss: 4.3287 accuracy: 0.0412\n",
            "\n",
            "Epoch 3/149\n",
            "----------\n",
            "train loss: 2.9579 accuracy: 0.2814\n",
            "val loss: 3.6928 accuracy: 0.1176\n",
            "\n",
            "Epoch 4/149\n",
            "----------\n",
            "train loss: 2.7434 accuracy: 0.3480\n",
            "val loss: 3.1555 accuracy: 0.2304\n",
            "\n",
            "Epoch 5/149\n",
            "----------\n",
            "train loss: 2.6706 accuracy: 0.3706\n",
            "val loss: 2.7945 accuracy: 0.3441\n",
            "\n",
            "Epoch 6/149\n",
            "----------\n",
            "train loss: 2.5587 accuracy: 0.3853\n",
            "val loss: 2.6691 accuracy: 0.3735\n",
            "\n",
            "Epoch 7/149\n",
            "----------\n",
            "train loss: 2.5447 accuracy: 0.3941\n",
            "val loss: 2.6498 accuracy: 0.3833\n",
            "\n",
            "Epoch 8/149\n",
            "----------\n",
            "train loss: 2.5709 accuracy: 0.3892\n",
            "val loss: 2.6301 accuracy: 0.3833\n",
            "\n",
            "Epoch 9/149\n",
            "----------\n",
            "train loss: 2.5423 accuracy: 0.3833\n",
            "val loss: 2.5975 accuracy: 0.3873\n",
            "\n",
            "Epoch 10/149\n",
            "----------\n",
            "train loss: 2.4248 accuracy: 0.4324\n",
            "val loss: 2.5334 accuracy: 0.4010\n",
            "\n",
            "Epoch 11/149\n",
            "----------\n",
            "train loss: 2.3782 accuracy: 0.4206\n",
            "val loss: 2.5315 accuracy: 0.4010\n",
            "\n",
            "Epoch 12/149\n",
            "----------\n",
            "train loss: 2.2662 accuracy: 0.4559\n",
            "val loss: 2.5295 accuracy: 0.3716\n",
            "\n",
            "Epoch 13/149\n",
            "----------\n",
            "train loss: 2.2407 accuracy: 0.4716\n",
            "val loss: 2.4418 accuracy: 0.3882\n",
            "\n",
            "Epoch 14/149\n",
            "----------\n",
            "train loss: 2.1031 accuracy: 0.5029\n",
            "val loss: 2.4628 accuracy: 0.3892\n",
            "\n",
            "Epoch 15/149\n",
            "----------\n",
            "train loss: 2.0358 accuracy: 0.4951\n",
            "val loss: 2.3548 accuracy: 0.4255\n",
            "\n",
            "Epoch 16/149\n",
            "----------\n",
            "train loss: 1.9183 accuracy: 0.5324\n",
            "val loss: 2.3061 accuracy: 0.4294\n",
            "\n",
            "Epoch 17/149\n",
            "----------\n",
            "train loss: 1.8697 accuracy: 0.5284\n",
            "val loss: 2.1963 accuracy: 0.4559\n",
            "\n",
            "Epoch 18/149\n",
            "----------\n",
            "train loss: 1.7839 accuracy: 0.5647\n",
            "val loss: 2.1253 accuracy: 0.4804\n",
            "\n",
            "Epoch 19/149\n",
            "----------\n",
            "train loss: 1.6231 accuracy: 0.6157\n",
            "val loss: 2.0884 accuracy: 0.4922\n",
            "\n",
            "Epoch 20/149\n",
            "----------\n",
            "train loss: 1.6062 accuracy: 0.6127\n",
            "val loss: 2.0740 accuracy: 0.4980\n",
            "\n",
            "Epoch 21/149\n",
            "----------\n",
            "train loss: 1.6768 accuracy: 0.6010\n",
            "val loss: 2.0709 accuracy: 0.5000\n",
            "\n",
            "Epoch 22/149\n",
            "----------\n",
            "train loss: 1.6143 accuracy: 0.6324\n",
            "val loss: 2.0570 accuracy: 0.5039\n",
            "\n",
            "Epoch 23/149\n",
            "----------\n",
            "train loss: 1.5918 accuracy: 0.6255\n",
            "val loss: 2.0492 accuracy: 0.4951\n",
            "\n",
            "Epoch 24/149\n",
            "----------\n",
            "train loss: 1.6166 accuracy: 0.6186\n",
            "val loss: 2.0358 accuracy: 0.4971\n",
            "\n",
            "Epoch 25/149\n",
            "----------\n",
            "train loss: 1.6602 accuracy: 0.5843\n",
            "val loss: 2.0689 accuracy: 0.5059\n",
            "\n",
            "Epoch 26/149\n",
            "----------\n",
            "train loss: 1.5617 accuracy: 0.6265\n",
            "val loss: 2.1120 accuracy: 0.4794\n",
            "\n",
            "Epoch 27/149\n",
            "----------\n",
            "train loss: 1.6202 accuracy: 0.6137\n",
            "val loss: 2.1652 accuracy: 0.4804\n",
            "\n",
            "Epoch 28/149\n",
            "----------\n",
            "train loss: 1.5700 accuracy: 0.6265\n",
            "val loss: 2.2245 accuracy: 0.4549\n",
            "\n",
            "Epoch 29/149\n",
            "----------\n",
            "train loss: 1.5661 accuracy: 0.6206\n",
            "val loss: 2.1459 accuracy: 0.4725\n",
            "\n",
            "Epoch 30/149\n",
            "----------\n",
            "train loss: 1.5531 accuracy: 0.6431\n",
            "val loss: 2.0604 accuracy: 0.4892\n",
            "\n",
            "Epoch 31/149\n",
            "----------\n",
            "train loss: 1.4121 accuracy: 0.6647\n",
            "val loss: 2.0071 accuracy: 0.4853\n",
            "\n",
            "Epoch 32/149\n",
            "----------\n",
            "train loss: 1.3428 accuracy: 0.6863\n",
            "val loss: 1.9654 accuracy: 0.5069\n",
            "\n",
            "Epoch 33/149\n",
            "----------\n",
            "train loss: 1.3267 accuracy: 0.6882\n",
            "val loss: 1.9208 accuracy: 0.5216\n",
            "\n",
            "Epoch 34/149\n",
            "----------\n",
            "train loss: 1.2531 accuracy: 0.7245\n",
            "val loss: 1.9010 accuracy: 0.5353\n",
            "\n",
            "Epoch 35/149\n",
            "----------\n",
            "train loss: 1.2456 accuracy: 0.7245\n",
            "val loss: 1.8989 accuracy: 0.5314\n",
            "\n",
            "Epoch 36/149\n",
            "----------\n",
            "train loss: 1.2468 accuracy: 0.7353\n",
            "val loss: 1.8931 accuracy: 0.5363\n",
            "\n",
            "Epoch 37/149\n",
            "----------\n",
            "train loss: 1.1831 accuracy: 0.7333\n",
            "val loss: 1.9124 accuracy: 0.5275\n",
            "\n",
            "Epoch 38/149\n",
            "----------\n",
            "train loss: 1.1774 accuracy: 0.7520\n",
            "val loss: 1.9000 accuracy: 0.5333\n",
            "\n",
            "Epoch 39/149\n",
            "----------\n",
            "train loss: 1.2092 accuracy: 0.7284\n",
            "val loss: 1.8916 accuracy: 0.5510\n",
            "\n",
            "Epoch 40/149\n",
            "----------\n",
            "train loss: 1.1957 accuracy: 0.7314\n",
            "val loss: 1.9843 accuracy: 0.5010\n",
            "\n",
            "Epoch 41/149\n",
            "----------\n",
            "train loss: 1.2177 accuracy: 0.7088\n",
            "val loss: 1.9837 accuracy: 0.5176\n",
            "\n",
            "Epoch 42/149\n",
            "----------\n",
            "train loss: 1.2772 accuracy: 0.6824\n",
            "val loss: 2.0818 accuracy: 0.4922\n",
            "\n",
            "Epoch 43/149\n",
            "----------\n",
            "train loss: 1.2757 accuracy: 0.7000\n",
            "val loss: 2.0230 accuracy: 0.5010\n",
            "\n",
            "Epoch 44/149\n",
            "----------\n",
            "train loss: 1.2016 accuracy: 0.7333\n",
            "val loss: 1.9853 accuracy: 0.5147\n",
            "\n",
            "Epoch 45/149\n",
            "----------\n",
            "train loss: 1.2230 accuracy: 0.7167\n",
            "val loss: 1.9954 accuracy: 0.5127\n",
            "\n",
            "Epoch 46/149\n",
            "----------\n",
            "train loss: 1.0599 accuracy: 0.7578\n",
            "val loss: 1.8869 accuracy: 0.5500\n",
            "\n",
            "Epoch 47/149\n",
            "----------\n",
            "train loss: 1.0402 accuracy: 0.7696\n",
            "val loss: 1.8478 accuracy: 0.5598\n",
            "\n",
            "Epoch 48/149\n",
            "----------\n",
            "train loss: 1.0203 accuracy: 0.7657\n",
            "val loss: 1.8268 accuracy: 0.5618\n",
            "\n",
            "Epoch 49/149\n",
            "----------\n",
            "train loss: 1.0207 accuracy: 0.7735\n",
            "val loss: 1.8273 accuracy: 0.5657\n",
            "\n",
            "Epoch 50/149\n",
            "----------\n",
            "train loss: 1.0383 accuracy: 0.7696\n",
            "val loss: 1.8168 accuracy: 0.5667\n",
            "\n",
            "Epoch 51/149\n",
            "----------\n",
            "train loss: 1.0265 accuracy: 0.7676\n",
            "val loss: 1.8169 accuracy: 0.5676\n",
            "\n",
            "Epoch 52/149\n",
            "----------\n",
            "train loss: 0.9734 accuracy: 0.7775\n",
            "val loss: 1.8522 accuracy: 0.5578\n",
            "\n",
            "Epoch 53/149\n",
            "----------\n",
            "train loss: 1.0202 accuracy: 0.7696\n",
            "val loss: 1.8761 accuracy: 0.5373\n",
            "\n",
            "Epoch 54/149\n",
            "----------\n",
            "train loss: 0.9920 accuracy: 0.7716\n",
            "val loss: 1.9006 accuracy: 0.5373\n",
            "\n",
            "Epoch 55/149\n",
            "----------\n",
            "train loss: 1.0322 accuracy: 0.7647\n",
            "val loss: 1.9356 accuracy: 0.5255\n",
            "\n",
            "Epoch 56/149\n",
            "----------\n",
            "train loss: 1.0417 accuracy: 0.7510\n",
            "val loss: 1.9681 accuracy: 0.4961\n",
            "\n",
            "Epoch 57/149\n",
            "----------\n",
            "train loss: 1.0822 accuracy: 0.7461\n",
            "val loss: 1.8999 accuracy: 0.5304\n",
            "\n",
            "Epoch 58/149\n",
            "----------\n",
            "train loss: 1.0050 accuracy: 0.7618\n",
            "val loss: 1.9149 accuracy: 0.5333\n",
            "\n",
            "Epoch 59/149\n",
            "----------\n",
            "train loss: 0.9965 accuracy: 0.7667\n",
            "val loss: 1.8711 accuracy: 0.5412\n",
            "\n",
            "Epoch 60/149\n",
            "----------\n",
            "train loss: 0.9301 accuracy: 0.7980\n",
            "val loss: 1.7938 accuracy: 0.5598\n",
            "\n",
            "Epoch 61/149\n",
            "----------\n",
            "train loss: 0.8285 accuracy: 0.8245\n",
            "val loss: 1.7907 accuracy: 0.5716\n",
            "\n",
            "Epoch 62/149\n",
            "----------\n",
            "train loss: 0.8608 accuracy: 0.8088\n",
            "val loss: 1.7814 accuracy: 0.5735\n",
            "\n",
            "Epoch 63/149\n",
            "----------\n",
            "train loss: 0.8250 accuracy: 0.8235\n",
            "val loss: 1.7794 accuracy: 0.5716\n",
            "\n",
            "Epoch 64/149\n",
            "----------\n",
            "train loss: 0.8698 accuracy: 0.7931\n",
            "val loss: 1.7624 accuracy: 0.5794\n",
            "\n",
            "Epoch 65/149\n",
            "----------\n",
            "train loss: 0.7988 accuracy: 0.8206\n",
            "val loss: 1.7825 accuracy: 0.5667\n",
            "\n",
            "Epoch 66/149\n",
            "----------\n",
            "train loss: 0.8185 accuracy: 0.8304\n",
            "val loss: 1.8172 accuracy: 0.5569\n",
            "\n",
            "Epoch 67/149\n",
            "----------\n",
            "train loss: 0.8374 accuracy: 0.8176\n",
            "val loss: 1.7978 accuracy: 0.5647\n",
            "\n",
            "Epoch 68/149\n",
            "----------\n",
            "train loss: 0.9238 accuracy: 0.7863\n",
            "val loss: 1.8546 accuracy: 0.5451\n",
            "\n",
            "Epoch 69/149\n",
            "----------\n",
            "train loss: 0.9637 accuracy: 0.7873\n",
            "val loss: 1.8985 accuracy: 0.5490\n",
            "\n",
            "Epoch 70/149\n",
            "----------\n",
            "train loss: 0.9453 accuracy: 0.7755\n",
            "val loss: 1.9072 accuracy: 0.5245\n",
            "\n",
            "Epoch 71/149\n",
            "----------\n",
            "train loss: 0.9261 accuracy: 0.7902\n",
            "val loss: 1.9269 accuracy: 0.5412\n",
            "\n",
            "Epoch 72/149\n",
            "----------\n",
            "train loss: 0.8660 accuracy: 0.8049\n",
            "val loss: 1.8854 accuracy: 0.5392\n",
            "\n",
            "Epoch 73/149\n",
            "----------\n",
            "train loss: 0.8356 accuracy: 0.8167\n",
            "val loss: 1.8167 accuracy: 0.5627\n",
            "\n",
            "Epoch 74/149\n",
            "----------\n",
            "train loss: 0.7860 accuracy: 0.8265\n",
            "val loss: 1.7734 accuracy: 0.5843\n",
            "\n",
            "Epoch 75/149\n",
            "----------\n",
            "train loss: 0.7547 accuracy: 0.8510\n",
            "val loss: 1.7154 accuracy: 0.5971\n",
            "\n",
            "Epoch 76/149\n",
            "----------\n",
            "train loss: 0.6682 accuracy: 0.8578\n",
            "val loss: 1.7051 accuracy: 0.5961\n",
            "\n",
            "Epoch 77/149\n",
            "----------\n",
            "train loss: 0.7714 accuracy: 0.8275\n",
            "val loss: 1.7098 accuracy: 0.5941\n",
            "\n",
            "Epoch 78/149\n",
            "----------\n",
            "train loss: 0.7667 accuracy: 0.8314\n",
            "val loss: 1.7055 accuracy: 0.5902\n",
            "\n",
            "Epoch 79/149\n",
            "----------\n",
            "train loss: 0.6763 accuracy: 0.8775\n",
            "val loss: 1.7272 accuracy: 0.5814\n",
            "\n",
            "Epoch 80/149\n",
            "----------\n",
            "train loss: 0.7041 accuracy: 0.8480\n",
            "val loss: 1.7502 accuracy: 0.5824\n",
            "\n",
            "Epoch 81/149\n",
            "----------\n",
            "train loss: 0.7510 accuracy: 0.8441\n",
            "val loss: 1.7724 accuracy: 0.5765\n",
            "\n",
            "Epoch 82/149\n",
            "----------\n",
            "train loss: 0.7871 accuracy: 0.8196\n",
            "val loss: 1.7967 accuracy: 0.5725\n",
            "\n",
            "Epoch 83/149\n",
            "----------\n",
            "train loss: 0.7901 accuracy: 0.8137\n",
            "val loss: 1.9059 accuracy: 0.5451\n",
            "\n",
            "Epoch 84/149\n",
            "----------\n",
            "train loss: 0.8218 accuracy: 0.7971\n",
            "val loss: 1.8812 accuracy: 0.5471\n",
            "\n",
            "Epoch 85/149\n",
            "----------\n",
            "train loss: 0.7953 accuracy: 0.8088\n",
            "val loss: 1.8781 accuracy: 0.5441\n",
            "\n",
            "Epoch 86/149\n",
            "----------\n",
            "train loss: 0.8292 accuracy: 0.8196\n",
            "val loss: 1.8547 accuracy: 0.5569\n",
            "\n",
            "Epoch 87/149\n",
            "----------\n",
            "train loss: 0.7698 accuracy: 0.8284\n",
            "val loss: 1.7891 accuracy: 0.5676\n",
            "\n",
            "Epoch 88/149\n",
            "----------\n",
            "train loss: 0.6990 accuracy: 0.8431\n",
            "val loss: 1.7723 accuracy: 0.5794\n",
            "\n",
            "Epoch 89/149\n",
            "----------\n",
            "train loss: 0.7323 accuracy: 0.8333\n",
            "val loss: 1.7356 accuracy: 0.5941\n",
            "\n",
            "Epoch 90/149\n",
            "----------\n",
            "train loss: 0.6430 accuracy: 0.8735\n",
            "val loss: 1.7167 accuracy: 0.6010\n",
            "\n",
            "Epoch 91/149\n",
            "----------\n",
            "train loss: 0.6279 accuracy: 0.8755\n",
            "val loss: 1.7178 accuracy: 0.5961\n",
            "\n",
            "Epoch 92/149\n",
            "----------\n",
            "train loss: 0.6634 accuracy: 0.8569\n",
            "val loss: 1.7087 accuracy: 0.5961\n",
            "\n",
            "Epoch 93/149\n",
            "----------\n",
            "train loss: 0.6057 accuracy: 0.8686\n",
            "val loss: 1.6936 accuracy: 0.5990\n",
            "\n",
            "Epoch 94/149\n",
            "----------\n",
            "train loss: 0.6416 accuracy: 0.8696\n",
            "val loss: 1.7214 accuracy: 0.5912\n",
            "\n",
            "Epoch 95/149\n",
            "----------\n",
            "train loss: 0.6349 accuracy: 0.8706\n",
            "val loss: 1.8141 accuracy: 0.5676\n",
            "\n",
            "Epoch 96/149\n",
            "----------\n",
            "train loss: 0.6564 accuracy: 0.8529\n",
            "val loss: 1.8224 accuracy: 0.5598\n",
            "\n",
            "Epoch 97/149\n",
            "----------\n",
            "train loss: 0.7157 accuracy: 0.8314\n",
            "val loss: 1.8685 accuracy: 0.5480\n",
            "\n",
            "Epoch 98/149\n",
            "----------\n",
            "train loss: 0.7919 accuracy: 0.8206\n",
            "val loss: 1.9155 accuracy: 0.5373\n",
            "\n",
            "Epoch 99/149\n",
            "----------\n",
            "train loss: 0.7480 accuracy: 0.8294\n",
            "val loss: 1.8724 accuracy: 0.5598\n",
            "\n",
            "Epoch 100/149\n",
            "----------\n",
            "train loss: 0.7660 accuracy: 0.8373\n",
            "val loss: 1.8267 accuracy: 0.5598\n",
            "\n",
            "Epoch 101/149\n",
            "----------\n",
            "train loss: 0.6647 accuracy: 0.8412\n",
            "val loss: 1.7941 accuracy: 0.5676\n",
            "\n",
            "Epoch 102/149\n",
            "----------\n",
            "train loss: 0.6353 accuracy: 0.8657\n",
            "val loss: 1.7506 accuracy: 0.5824\n",
            "\n",
            "Epoch 103/149\n",
            "----------\n",
            "train loss: 0.6041 accuracy: 0.8618\n",
            "val loss: 1.7112 accuracy: 0.6049\n",
            "\n",
            "Epoch 104/149\n",
            "----------\n",
            "train loss: 0.5924 accuracy: 0.8667\n",
            "val loss: 1.6990 accuracy: 0.6088\n",
            "\n",
            "Epoch 105/149\n",
            "----------\n",
            "train loss: 0.5502 accuracy: 0.8765\n",
            "val loss: 1.6983 accuracy: 0.6078\n",
            "\n",
            "Epoch 106/149\n",
            "----------\n",
            "train loss: 0.5579 accuracy: 0.8755\n",
            "val loss: 1.6879 accuracy: 0.6039\n",
            "\n",
            "Epoch 107/149\n",
            "----------\n",
            "train loss: 0.5703 accuracy: 0.8775\n",
            "val loss: 1.6994 accuracy: 0.6088\n",
            "\n",
            "Epoch 108/149\n",
            "----------\n",
            "train loss: 0.5491 accuracy: 0.8824\n",
            "val loss: 1.7093 accuracy: 0.5990\n",
            "\n",
            "Epoch 109/149\n",
            "----------\n",
            "train loss: 0.5647 accuracy: 0.8824\n",
            "val loss: 1.7463 accuracy: 0.5667\n",
            "\n",
            "Epoch 110/149\n",
            "----------\n",
            "train loss: 0.5919 accuracy: 0.8765\n",
            "val loss: 1.8595 accuracy: 0.5549\n",
            "\n",
            "Epoch 111/149\n",
            "----------\n",
            "train loss: 0.6009 accuracy: 0.8696\n",
            "val loss: 1.8912 accuracy: 0.5578\n",
            "\n",
            "Epoch 112/149\n",
            "----------\n",
            "train loss: 0.6857 accuracy: 0.8304\n",
            "val loss: 1.9108 accuracy: 0.5333\n",
            "\n",
            "Epoch 113/149\n",
            "----------\n",
            "train loss: 0.6700 accuracy: 0.8490\n",
            "val loss: 1.8581 accuracy: 0.5520\n",
            "\n",
            "Epoch 114/149\n",
            "----------\n",
            "train loss: 0.6529 accuracy: 0.8441\n",
            "val loss: 1.9332 accuracy: 0.5441\n",
            "\n",
            "Epoch 115/149\n",
            "----------\n",
            "train loss: 0.6421 accuracy: 0.8637\n",
            "val loss: 1.8402 accuracy: 0.5598\n",
            "\n",
            "Epoch 116/149\n",
            "----------\n",
            "train loss: 0.5526 accuracy: 0.8814\n",
            "val loss: 1.7378 accuracy: 0.5853\n",
            "\n",
            "Epoch 117/149\n",
            "----------\n",
            "train loss: 0.5935 accuracy: 0.8657\n",
            "val loss: 1.7148 accuracy: 0.6029\n",
            "\n",
            "Epoch 118/149\n",
            "----------\n",
            "train loss: 0.5143 accuracy: 0.8863\n",
            "val loss: 1.7012 accuracy: 0.6108\n",
            "\n",
            "Epoch 119/149\n",
            "----------\n",
            "train loss: 0.5279 accuracy: 0.8863\n",
            "val loss: 1.6966 accuracy: 0.6088\n",
            "\n",
            "Epoch 120/149\n",
            "----------\n",
            "train loss: 0.5046 accuracy: 0.8853\n",
            "val loss: 1.6986 accuracy: 0.5990\n",
            "\n",
            "Epoch 121/149\n",
            "----------\n",
            "train loss: 0.5105 accuracy: 0.8873\n",
            "val loss: 1.7285 accuracy: 0.6039\n",
            "\n",
            "Epoch 122/149\n",
            "----------\n",
            "train loss: 0.4985 accuracy: 0.8892\n",
            "val loss: 1.7078 accuracy: 0.5971\n",
            "\n",
            "Epoch 123/149\n",
            "----------\n",
            "train loss: 0.4985 accuracy: 0.8961\n",
            "val loss: 1.7571 accuracy: 0.5755\n",
            "\n",
            "Epoch 124/149\n",
            "----------\n",
            "train loss: 0.5496 accuracy: 0.8824\n",
            "val loss: 1.8442 accuracy: 0.5637\n",
            "\n",
            "Epoch 125/149\n",
            "----------\n",
            "train loss: 0.6106 accuracy: 0.8549\n",
            "val loss: 1.8148 accuracy: 0.5784\n",
            "\n",
            "Epoch 126/149\n",
            "----------\n",
            "train loss: 0.5367 accuracy: 0.8775\n",
            "val loss: 1.8790 accuracy: 0.5647\n",
            "\n",
            "Epoch 127/149\n",
            "----------\n",
            "train loss: 0.6215 accuracy: 0.8500\n",
            "val loss: 1.9854 accuracy: 0.5147\n",
            "\n",
            "Epoch 128/149\n",
            "----------\n",
            "train loss: 0.6458 accuracy: 0.8578\n",
            "val loss: 1.9444 accuracy: 0.5402\n",
            "\n",
            "Epoch 129/149\n",
            "----------\n",
            "train loss: 0.5780 accuracy: 0.8657\n",
            "val loss: 1.8255 accuracy: 0.5706\n",
            "\n",
            "Epoch 130/149\n",
            "----------\n",
            "train loss: 0.5661 accuracy: 0.8686\n",
            "val loss: 1.7190 accuracy: 0.6059\n",
            "\n",
            "Epoch 131/149\n",
            "----------\n",
            "train loss: 0.5587 accuracy: 0.8637\n",
            "val loss: 1.6895 accuracy: 0.6225\n",
            "\n",
            "Epoch 132/149\n",
            "----------\n",
            "train loss: 0.5075 accuracy: 0.8794\n",
            "val loss: 1.6800 accuracy: 0.6294\n",
            "\n",
            "Epoch 133/149\n",
            "----------\n",
            "train loss: 0.5185 accuracy: 0.8853\n",
            "val loss: 1.6790 accuracy: 0.6275\n",
            "\n",
            "Epoch 134/149\n",
            "----------\n",
            "train loss: 0.4550 accuracy: 0.9029\n",
            "val loss: 1.6762 accuracy: 0.6186\n",
            "\n",
            "Epoch 135/149\n",
            "----------\n",
            "train loss: 0.4650 accuracy: 0.9039\n",
            "val loss: 1.6954 accuracy: 0.6137\n",
            "\n",
            "Epoch 136/149\n",
            "----------\n",
            "train loss: 0.5043 accuracy: 0.8912\n",
            "val loss: 1.6943 accuracy: 0.6108\n",
            "\n",
            "Epoch 137/149\n",
            "----------\n",
            "train loss: 0.4773 accuracy: 0.8951\n",
            "val loss: 1.7755 accuracy: 0.5843\n",
            "\n",
            "Epoch 138/149\n",
            "----------\n",
            "train loss: 0.4786 accuracy: 0.9039\n",
            "val loss: 1.8476 accuracy: 0.5657\n",
            "\n",
            "Epoch 139/149\n",
            "----------\n",
            "train loss: 0.5371 accuracy: 0.8784\n",
            "val loss: 1.9009 accuracy: 0.5667\n",
            "\n",
            "Epoch 140/149\n",
            "----------\n",
            "train loss: 0.5891 accuracy: 0.8676\n",
            "val loss: 1.8940 accuracy: 0.5451\n",
            "\n",
            "Epoch 141/149\n",
            "----------\n",
            "train loss: 0.5775 accuracy: 0.8657\n",
            "val loss: 1.8713 accuracy: 0.5422\n",
            "\n",
            "Epoch 142/149\n",
            "----------\n",
            "train loss: 0.5392 accuracy: 0.8745\n",
            "val loss: 1.9148 accuracy: 0.5549\n",
            "\n",
            "Epoch 143/149\n",
            "----------\n",
            "train loss: 0.5601 accuracy: 0.8784\n",
            "val loss: 1.7844 accuracy: 0.5794\n",
            "\n",
            "Epoch 144/149\n",
            "----------\n",
            "train loss: 0.4975 accuracy: 0.8931\n",
            "val loss: 1.7468 accuracy: 0.5853\n",
            "\n",
            "Epoch 145/149\n",
            "----------\n",
            "train loss: 0.4929 accuracy: 0.8931\n",
            "val loss: 1.6981 accuracy: 0.6010\n",
            "\n",
            "Epoch 146/149\n",
            "----------\n",
            "train loss: 0.4475 accuracy: 0.9029\n",
            "val loss: 1.6691 accuracy: 0.6039\n",
            "\n",
            "Epoch 147/149\n",
            "----------\n",
            "train loss: 0.4609 accuracy: 0.8931\n",
            "val loss: 1.6629 accuracy: 0.6118\n",
            "\n",
            "Epoch 148/149\n",
            "----------\n",
            "train loss: 0.4759 accuracy: 0.8980\n",
            "val loss: 1.6482 accuracy: 0.6108\n",
            "\n",
            "Epoch 149/149\n",
            "----------\n",
            "train loss: 0.4149 accuracy: 0.9176\n",
            "val loss: 1.6514 accuracy: 0.6108\n",
            "\n",
            "Training completed in 52m 16s\n",
            "Best val accuracy: 0.629412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6ejU3BQpHV4"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'flowers102_classifier_model.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model for evaluation\n",
        "model.load_state_dict(torch.load('flowers102_classifier_model.pth'))\n",
        "model.eval()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnlkvn2gW3Xc",
        "outputId": "193bf417-2fd0-42e9-bded-152f0a164746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FlowerCNN(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (bn6): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=102, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate accuracy\n",
        "def evaluate_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "YLXa6rtjW5nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_accuracy = evaluate_model(model, dataloaders['test'])\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgMhkBHQW7eJ",
        "outputId": "4b4b834e-4cfc-4455-c33a-38496853b1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 55.34%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}